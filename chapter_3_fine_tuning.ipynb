{
 "cells": [
  {
   "cell_type": "code",
   "id": "7aed513edbe48b24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:31:52.577057Z",
     "start_time": "2025-04-01T12:31:52.573674Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T16:44:03.749009Z",
     "start_time": "2025-03-31T16:44:03.161399Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  2023,  2607,  2003,  6429,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11,
   "source": [
    "\n",
    "# Same as before\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\n",
    "]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "batch"
   ],
   "id": "d51611c741a3acf0"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:44:10.788402Z",
     "start_time": "2025-03-31T16:44:10.783187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is new\n",
    "batch[\"labels\"] = torch.tensor([1, 1])\n",
    "batch"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  2023,  2607,  2003,  6429,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:51:35.294101Z",
     "start_time": "2025-03-31T06:51:34.617842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = AdamW(model.parameters())\n",
    "loss = model(**batch).loss\n",
    "loss"
   ],
   "id": "f3f5aca3b7b8f021",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4148, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T06:51:38.772013Z",
     "start_time": "2025-03-31T06:51:37.957951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ],
   "id": "802063e5fd2c17d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T07:59:16.877815Z",
     "start_time": "2025-04-01T07:59:08.975199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ],
   "id": "df92d6aecf974711",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Generating train split: 100%|██████████| 3668/3668 [00:00<00:00, 284954.75 examples/s]\n",
      "Generating validation split: 100%|██████████| 408/408 [00:00<00:00, 139821.56 examples/s]\n",
      "Generating test split: 100%|██████████| 1725/1725 [00:00<00:00, 524022.19 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:03:43.381788Z",
     "start_time": "2025-04-01T08:03:43.378965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[15]"
   ],
   "id": "96665b7bf5f1be50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .',\n",
       " 'sentence2': 'Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .',\n",
       " 'label': 0,\n",
       " 'idx': 16}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:02:57.355501Z",
     "start_time": "2025-04-01T08:02:57.351184Z"
    }
   },
   "cell_type": "code",
   "source": "raw_train_dataset.features",
   "id": "fbd0db5899a5d70f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:09:18.903564Z",
     "start_time": "2025-04-01T08:09:18.292842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"sentence1\"])\n",
    "tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"sentence2\"])"
   ],
   "id": "651a8ee7fe0431bd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:09:59.961066Z",
     "start_time": "2025-04-01T08:09:59.958319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
    "inputs"
   ],
   "id": "5a3ecf074c901b28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:13:02.365593Z",
     "start_time": "2025-04-01T08:13:02.358012Z"
    }
   },
   "cell_type": "code",
   "source": "raw_train_dataset[15]",
   "id": "34ec769e0c9bcaa0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Rudder was most recently senior vice president for the Developer & Platform Evangelism Business .',\n",
       " 'sentence2': 'Senior Vice President Eric Rudder , formerly head of the Developer and Platform Evangelism unit , will lead the new entity .',\n",
       " 'label': 0,\n",
       " 'idx': 16}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:14:02.181616Z",
     "start_time": "2025-04-01T08:14:01.979704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = tokenizer(raw_train_dataset['sentence1'], raw_train_dataset['sentence2'])\n",
    "inputs.keys()"
   ],
   "id": "efff079a7843012f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:16:04.398398Z",
     "start_time": "2025-04-01T08:16:04.395110Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(inputs['input_ids'][10])",
   "id": "d068f42a1f89e3a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] legislation making it harder for consumers to erase their debts in bankruptcy court won overwhelming house approval in march. [SEP] legislation making it harder for consumers to erase their debts in bankruptcy court won speedy, house approval in march and was endorsed by the white house. [SEP]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:26:09.123907Z",
     "start_time": "2025-04-01T08:26:09.120009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ],
   "id": "8a1aab570a61f5ce",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:28:51.141734Z",
     "start_time": "2025-04-01T08:28:51.012634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ],
   "id": "a2833c999fcdafc5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3668/3668 [00:00<00:00, 31978.79 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:28:55.093268Z",
     "start_time": "2025-04-01T08:28:55.089340Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_datasets['train']",
   "id": "90fd2c7776c33662",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T08:27:32.265416Z",
     "start_time": "2025-04-01T08:27:32.261940Z"
    }
   },
   "cell_type": "code",
   "source": "raw_datasets['train']",
   "id": "471ac5412b230c9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:21:52.032886Z",
     "start_time": "2025-04-01T09:21:51.941354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ],
   "id": "7179084569b7c7e0",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[50]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TrainingArguments\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m training_args = \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtest-trainer\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<string>:135\u001B[39m, in \u001B[36m__init__\u001B[39m\u001B[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, tp_size, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/training_args.py:1808\u001B[39m, in \u001B[36mTrainingArguments.__post_init__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1806\u001B[39m \u001B[38;5;66;03m# Initialize device before we proceed\u001B[39;00m\n\u001B[32m   1807\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_torch_available():\n\u001B[32m-> \u001B[39m\u001B[32m1808\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\n\u001B[32m   1810\u001B[39m \u001B[38;5;66;03m# Disable average tokens when using single device\u001B[39;00m\n\u001B[32m   1811\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.average_tokens_across_devices:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/training_args.py:2344\u001B[39m, in \u001B[36mTrainingArguments.device\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2340\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2341\u001B[39m \u001B[33;03mThe device used by this process.\u001B[39;00m\n\u001B[32m   2342\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2343\u001B[39m requires_backends(\u001B[38;5;28mself\u001B[39m, [\u001B[33m\"\u001B[39m\u001B[33mtorch\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m-> \u001B[39m\u001B[32m2344\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_setup_devices\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:62\u001B[39m, in \u001B[36mcached_property.__get__\u001B[39m\u001B[34m(self, obj, objtype)\u001B[39m\n\u001B[32m     60\u001B[39m cached = \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m     cached = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     63\u001B[39m     \u001B[38;5;28msetattr\u001B[39m(obj, attr, cached)\n\u001B[32m     64\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cached\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/training_args.py:2214\u001B[39m, in \u001B[36mTrainingArguments._setup_devices\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   2212\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[32m   2213\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[32m-> \u001B[39m\u001B[32m2214\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m   2215\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m`: \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2216\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPlease run `pip install transformers[torch]` or `pip install \u001B[39m\u001B[33m'\u001B[39m\u001B[33maccelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2217\u001B[39m         )\n\u001B[32m   2218\u001B[39m \u001B[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001B[39;00m\n\u001B[32m   2219\u001B[39m accelerator_state_kwargs = {\u001B[33m\"\u001B[39m\u001B[33menabled\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33muse_configured_state\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m}\n",
      "\u001B[31mImportError\u001B[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:35:44.433742Z",
     "start_time": "2025-04-01T09:35:44.424168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")\n",
    "\n",
    "training_args"
   ],
   "id": "7c18f2d5d4bc7e21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=False,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.NO,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=None,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=test-trainer/runs/Apr01_12-35-44_MacBook-Air-6.local,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3.0,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=test-trainer,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=test-trainer,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tp_size=0,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:36:38.998409Z",
     "start_time": "2025-04-01T09:36:31.286067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ],
   "id": "89df1b89ba906c55",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 408/408 [00:00<00:00, 22598.56 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:06:41.540898Z",
     "start_time": "2025-04-01T12:06:41.536171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    # tokenizer=tokenizer,\n",
    ")"
   ],
   "id": "9bf56340f8687177",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:09:53.694736Z",
     "start_time": "2025-04-01T12:07:04.189071Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "92aef512cd51da27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 536/1377 02:47 < 04:23, 3.19 it/s, Epoch 1.17/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.521900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:04]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/trainer.py:2556\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2549\u001B[39m context = (\n\u001B[32m   2550\u001B[39m     functools.partial(\u001B[38;5;28mself\u001B[39m.accelerator.no_sync, model=model)\n\u001B[32m   2551\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mlen\u001B[39m(batch_samples) - \u001B[32m1\u001B[39m\n\u001B[32m   2552\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001B[32m   2553\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext\n\u001B[32m   2554\u001B[39m )\n\u001B[32m   2555\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m-> \u001B[39m\u001B[32m2556\u001B[39m     tr_loss_step = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2558\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2559\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2560\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m   2561\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   2562\u001B[39m ):\n\u001B[32m   2563\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2564\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/trainer.py:3764\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   3761\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001B[32m   3762\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mscale_wrt_gas\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3764\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3766\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:2359\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   2357\u001B[39m     \u001B[38;5;28mself\u001B[39m.lomo_backward(loss, learning_rate)\n\u001B[32m   2358\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2359\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    616\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    617\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    618\u001B[39m         Tensor.backward,\n\u001B[32m    619\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    624\u001B[39m         inputs=inputs,\n\u001B[32m    625\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    628\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    342\u001B[39m     retain_graph = create_graph\n\u001B[32m    344\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    345\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    346\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m347\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    348\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    349\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    351\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    821\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    822\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m823\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    824\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    825\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    826\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    827\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:29:45.196713Z",
     "start_time": "2025-04-01T12:29:33.258441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ],
   "id": "c3dd94065b19b907",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:30:23.360300Z",
     "start_time": "2025-04-01T12:30:23.356556Z"
    }
   },
   "cell_type": "code",
   "source": "print(predictions)\n",
   "id": "c24e0683741fe979",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.548951  ,  2.5289629 ],\n",
      "       [ 1.7133213 , -0.8004892 ],\n",
      "       [ 1.237074  ,  0.3187242 ],\n",
      "       [-1.3754891 ,  2.5742872 ],\n",
      "       [ 1.5723387 , -2.0230572 ],\n",
      "       [-1.4189295 ,  2.5564141 ],\n",
      "       [-0.89375013,  2.144548  ],\n",
      "       [-1.4730521 ,  2.5937412 ],\n",
      "       [-1.1564559 ,  2.5287383 ],\n",
      "       [-1.5654689 ,  2.6084325 ],\n",
      "       [-1.652562  ,  2.6062315 ],\n",
      "       [ 0.05991198, -1.9134089 ],\n",
      "       [ 1.4843918 ,  0.54842085],\n",
      "       [-0.7842469 ,  2.3773038 ],\n",
      "       [-1.62699   ,  2.5696476 ],\n",
      "       [-0.7876283 ,  1.1292007 ],\n",
      "       [-1.6275835 ,  2.606839  ],\n",
      "       [ 1.0720603 ,  1.2767195 ],\n",
      "       [-1.7108523 ,  2.5920548 ],\n",
      "       [ 1.1188998 ,  1.2173035 ],\n",
      "       [ 1.8033475 , -0.85171705],\n",
      "       [-0.44604155,  2.2624524 ],\n",
      "       [-0.3979807 ,  0.7215038 ],\n",
      "       [-1.3858975 ,  2.4141376 ],\n",
      "       [-1.5194484 ,  2.5182526 ],\n",
      "       [-0.38283074,  2.1975844 ],\n",
      "       [-1.5111079 ,  2.453522  ],\n",
      "       [-1.6514832 ,  2.5576456 ],\n",
      "       [-1.4658043 ,  2.5506058 ],\n",
      "       [-1.4197806 ,  2.4436285 ],\n",
      "       [ 0.2641891 ,  1.2918493 ],\n",
      "       [-1.7216645 ,  2.588661  ],\n",
      "       [-1.346182  ,  2.551377  ],\n",
      "       [-0.84515166,  2.4312046 ],\n",
      "       [-1.5697421 ,  2.520963  ],\n",
      "       [-1.4297317 ,  2.5895498 ],\n",
      "       [ 0.966959  ,  0.76298857],\n",
      "       [ 1.0718166 , -1.5878848 ],\n",
      "       [-1.2358534 ,  2.3323348 ],\n",
      "       [-1.6676782 ,  2.5485713 ],\n",
      "       [ 1.0597898 ,  1.1898757 ],\n",
      "       [-0.99356186,  2.3171933 ],\n",
      "       [-0.06595223, -0.56644815],\n",
      "       [ 1.015345  ,  0.9173445 ],\n",
      "       [ 1.0513767 ,  1.3020521 ],\n",
      "       [-1.6655273 ,  2.596113  ],\n",
      "       [-1.635149  ,  2.5959184 ],\n",
      "       [ 1.5364821 , -0.51161534],\n",
      "       [-1.4130105 ,  2.4247715 ],\n",
      "       [-1.559457  ,  2.5267894 ],\n",
      "       [-1.2163728 ,  2.5109186 ],\n",
      "       [-0.96857196,  2.4420803 ],\n",
      "       [-1.2144943 ,  2.5445645 ],\n",
      "       [-1.3462548 ,  2.552924  ],\n",
      "       [-1.5484177 ,  2.6058235 ],\n",
      "       [-1.2998897 ,  2.496488  ],\n",
      "       [ 0.25737286,  1.8514014 ],\n",
      "       [-1.625147  ,  2.548568  ],\n",
      "       [-1.5879437 ,  2.509494  ],\n",
      "       [-1.4802349 ,  2.3982024 ],\n",
      "       [ 0.37540123,  0.11545138],\n",
      "       [-1.0451701 ,  2.4814265 ],\n",
      "       [-1.5347035 ,  2.5057874 ],\n",
      "       [-1.0290289 ,  2.4644368 ],\n",
      "       [-1.1607697 ,  2.5068486 ],\n",
      "       [ 1.2814846 ,  0.92715305],\n",
      "       [-1.6760087 ,  2.5999658 ],\n",
      "       [-1.4817458 ,  2.4080124 ],\n",
      "       [ 0.99143356, -0.770681  ],\n",
      "       [-1.537818  ,  2.5619428 ],\n",
      "       [-1.5438405 ,  2.5108578 ],\n",
      "       [ 0.87391037,  1.5232307 ],\n",
      "       [-1.6256386 ,  2.5441153 ],\n",
      "       [-1.4643846 ,  2.5475867 ],\n",
      "       [-1.2161499 ,  2.4163306 ],\n",
      "       [-1.1114985 ,  2.4211907 ],\n",
      "       [-0.6429008 ,  2.0466433 ],\n",
      "       [-1.6897548 ,  2.5674174 ],\n",
      "       [-1.3459958 ,  2.4013958 ],\n",
      "       [-1.3263412 ,  2.5357058 ],\n",
      "       [-0.911417  ,  2.4743826 ],\n",
      "       [-1.6106007 ,  2.492664  ],\n",
      "       [-1.4745389 ,  2.3059738 ],\n",
      "       [ 0.17362896,  1.6069251 ],\n",
      "       [-1.3617933 ,  2.5818489 ],\n",
      "       [-1.3618183 ,  2.3680265 ],\n",
      "       [-1.2962248 ,  2.4069674 ],\n",
      "       [ 1.4531142 , -0.26428837],\n",
      "       [-1.634262  ,  2.6019948 ],\n",
      "       [-1.7020304 ,  2.5764534 ],\n",
      "       [ 1.2549847 ,  0.47484887],\n",
      "       [-1.3598787 ,  2.541763  ],\n",
      "       [-1.4719659 ,  2.5375285 ],\n",
      "       [-1.5580364 ,  2.5395164 ],\n",
      "       [-1.4337424 ,  2.6066835 ],\n",
      "       [-1.5168605 ,  2.613384  ],\n",
      "       [ 0.56651735,  1.6363016 ],\n",
      "       [-0.62351865,  2.2351248 ],\n",
      "       [-1.2326555 ,  2.4333775 ],\n",
      "       [-1.3092269 ,  2.560567  ],\n",
      "       [-1.4329269 ,  2.4256244 ],\n",
      "       [ 0.6984562 ,  1.5311321 ],\n",
      "       [-1.1044861 ,  2.542536  ],\n",
      "       [-1.5138633 ,  2.5780363 ],\n",
      "       [-0.27871174,  0.78949183],\n",
      "       [-1.2492485 ,  2.3082223 ],\n",
      "       [-1.1543933 ,  2.4496145 ],\n",
      "       [ 1.6284695 ,  0.37098816],\n",
      "       [ 1.0502137 ,  1.0679325 ],\n",
      "       [-1.4315327 ,  2.521931  ],\n",
      "       [-1.0541776 ,  2.5182383 ],\n",
      "       [-0.1556404 ,  0.92434675],\n",
      "       [-1.2692081 ,  2.1749816 ],\n",
      "       [-1.6793517 ,  2.580499  ],\n",
      "       [-0.8763706 ,  2.4498484 ],\n",
      "       [-0.895003  ,  1.1131157 ],\n",
      "       [-1.5363445 ,  2.599226  ],\n",
      "       [-1.6298891 ,  2.5961905 ],\n",
      "       [-1.6151031 ,  2.6028295 ],\n",
      "       [-1.6262246 ,  2.5624125 ],\n",
      "       [-1.2749829 ,  2.600174  ],\n",
      "       [-0.6768797 ,  2.3397214 ],\n",
      "       [ 1.4561845 ,  0.12702936],\n",
      "       [-1.3454217 ,  2.141473  ],\n",
      "       [-1.6353241 ,  2.606421  ],\n",
      "       [-1.6600095 ,  2.511632  ],\n",
      "       [-1.517516  ,  2.5865188 ],\n",
      "       [ 1.3750874 ,  0.15551811],\n",
      "       [-1.6557581 ,  2.5999186 ],\n",
      "       [-1.4240762 ,  2.5814304 ],\n",
      "       [-1.5259424 ,  2.5802302 ],\n",
      "       [-0.99704176,  0.18841752],\n",
      "       [-0.4456584 ,  2.2220092 ],\n",
      "       [ 0.3724748 ,  0.86643517],\n",
      "       [-1.2076135 ,  2.4974744 ],\n",
      "       [-1.1549463 ,  2.4989927 ],\n",
      "       [-0.4404945 ,  1.1692576 ],\n",
      "       [ 1.2790908 ,  0.9344686 ],\n",
      "       [-1.6159593 ,  2.5898917 ],\n",
      "       [-1.4243165 ,  2.3794262 ],\n",
      "       [-1.6671051 ,  2.5884514 ],\n",
      "       [-1.4548078 ,  2.4293783 ],\n",
      "       [ 1.8607869 , -1.6465148 ],\n",
      "       [-1.1050351 ,  1.9825853 ],\n",
      "       [ 1.5353018 ,  0.00503811],\n",
      "       [-0.39365005,  2.250016  ],\n",
      "       [-1.683867  ,  2.6095762 ],\n",
      "       [-1.1951133 ,  2.3121674 ],\n",
      "       [-0.8291524 ,  2.2723224 ],\n",
      "       [-1.4849378 ,  2.5156925 ],\n",
      "       [ 1.3257855 ,  0.8051659 ],\n",
      "       [-1.4709646 ,  2.4310954 ],\n",
      "       [-0.13117385,  0.45060295],\n",
      "       [-1.6765978 ,  2.5900147 ],\n",
      "       [-0.7185567 ,  2.3524272 ],\n",
      "       [-1.3964936 ,  2.5347607 ],\n",
      "       [-1.4052485 ,  2.3922083 ],\n",
      "       [-1.2969595 ,  2.5429938 ],\n",
      "       [-1.0337833 ,  1.1591868 ],\n",
      "       [-1.1993766 ,  2.3956504 ],\n",
      "       [-1.3149589 ,  2.5919447 ],\n",
      "       [-1.4093591 ,  2.5203574 ],\n",
      "       [-1.6561656 ,  2.597247  ],\n",
      "       [-1.6726674 ,  2.5824757 ],\n",
      "       [-1.3437216 ,  2.4345064 ],\n",
      "       [-0.8969015 ,  2.4791665 ],\n",
      "       [-0.84370476,  2.437843  ],\n",
      "       [ 0.10582876, -2.037462  ],\n",
      "       [-1.1831365 ,  1.9294933 ],\n",
      "       [ 1.5655103 , -0.52065367],\n",
      "       [ 1.1233693 ,  1.188962  ],\n",
      "       [-0.08106329,  1.3305485 ],\n",
      "       [-0.20411737,  2.1165607 ],\n",
      "       [-1.6443509 ,  2.5731933 ],\n",
      "       [-1.3413569 ,  2.5479968 ],\n",
      "       [-1.346163  ,  2.5000913 ],\n",
      "       [-1.2182713 ,  2.473714  ],\n",
      "       [ 0.18963958,  1.4835726 ],\n",
      "       [-1.5708131 ,  2.4945543 ],\n",
      "       [-1.6484883 ,  2.5898552 ],\n",
      "       [-1.1448468 ,  2.4707687 ],\n",
      "       [-0.9447076 ,  1.8481613 ],\n",
      "       [-0.7872587 ,  1.9194117 ],\n",
      "       [-1.577809  ,  2.498327  ],\n",
      "       [-0.53597707,  1.3158183 ],\n",
      "       [-1.5873936 ,  2.4390273 ],\n",
      "       [ 1.0270044 ,  0.3292076 ],\n",
      "       [-0.7602915 ,  1.6123492 ],\n",
      "       [ 1.4814289 , -1.3540803 ],\n",
      "       [-1.3660342 ,  2.422911  ],\n",
      "       [-1.4727005 ,  2.5223556 ],\n",
      "       [ 1.3379453 , -0.05649594],\n",
      "       [-0.8257845 ,  1.9909946 ],\n",
      "       [-1.6173921 ,  2.5713785 ],\n",
      "       [-0.7158781 ,  2.3347862 ],\n",
      "       [-0.44711882,  2.2946162 ],\n",
      "       [-1.6605071 ,  2.5953166 ],\n",
      "       [-0.87426907,  2.4078228 ],\n",
      "       [-1.3396379 ,  2.3511615 ],\n",
      "       [-1.4428849 ,  2.5791738 ],\n",
      "       [-1.1139411 ,  2.2573085 ],\n",
      "       [-1.5225152 ,  2.3977764 ],\n",
      "       [ 0.9202322 ,  1.4014158 ],\n",
      "       [-0.794456  ,  2.4385536 ],\n",
      "       [-1.1317183 ,  2.534093  ],\n",
      "       [ 0.6439986 ,  1.5776371 ],\n",
      "       [-1.3660914 ,  2.513993  ],\n",
      "       [-1.0148323 ,  2.4567559 ],\n",
      "       [ 0.5789883 ,  1.6612092 ],\n",
      "       [-1.0355879 ,  1.9199997 ],\n",
      "       [-0.30732432,  1.7492634 ],\n",
      "       [-1.609733  ,  2.5381596 ],\n",
      "       [-0.8063725 ,  2.2821145 ],\n",
      "       [ 1.4962504 , -0.01943766],\n",
      "       [-1.4955847 ,  2.5121813 ],\n",
      "       [-1.6212875 ,  2.5359287 ],\n",
      "       [-1.3194424 ,  2.4853127 ],\n",
      "       [-1.5494378 ,  2.498889  ],\n",
      "       [ 1.6575022 ,  0.18547085],\n",
      "       [-1.1132121 ,  2.4942544 ],\n",
      "       [-1.1394397 ,  2.3133485 ],\n",
      "       [-0.81377167,  1.6853532 ],\n",
      "       [-1.450462  ,  2.4604483 ],\n",
      "       [ 1.4725367 ,  0.6198645 ],\n",
      "       [-1.4973416 ,  2.5536826 ],\n",
      "       [-1.5887976 ,  2.638467  ],\n",
      "       [-1.6100236 ,  2.568186  ],\n",
      "       [-0.9685408 ,  2.3864763 ],\n",
      "       [-1.5957929 ,  2.558676  ],\n",
      "       [-1.1787151 ,  2.3530948 ],\n",
      "       [-1.499602  ,  2.5537646 ],\n",
      "       [-1.0679209 ,  2.4150097 ],\n",
      "       [ 0.3781695 ,  1.7239709 ],\n",
      "       [-0.2977773 ,  0.8624285 ],\n",
      "       [-0.8564428 ,  2.25743   ],\n",
      "       [ 1.5269564 , -0.82268566],\n",
      "       [-0.6755064 ,  2.2495725 ],\n",
      "       [ 0.63621706,  1.5280148 ],\n",
      "       [-1.393658  ,  2.341572  ],\n",
      "       [-1.1126193 ,  2.5625143 ],\n",
      "       [-1.5121664 ,  2.5360599 ],\n",
      "       [ 1.4151367 , -0.23378019],\n",
      "       [-1.1999422 ,  2.385383  ],\n",
      "       [-1.1843505 ,  2.419819  ],\n",
      "       [-1.5718335 ,  2.4422357 ],\n",
      "       [-1.5512192 ,  2.5536475 ],\n",
      "       [-1.1236837 ,  2.4831655 ],\n",
      "       [-1.3333098 ,  2.550091  ],\n",
      "       [-1.2664396 ,  2.4963133 ],\n",
      "       [-0.4853278 ,  2.2944963 ],\n",
      "       [-1.3571554 ,  2.545498  ],\n",
      "       [-0.80754393,  1.498741  ],\n",
      "       [-0.5926009 ,  2.0243533 ],\n",
      "       [ 0.28687227,  1.7899671 ],\n",
      "       [ 1.0328993 ,  1.1405684 ],\n",
      "       [ 1.991126  , -0.9372462 ],\n",
      "       [-1.250991  ,  2.5481575 ],\n",
      "       [-1.4441725 ,  2.515475  ],\n",
      "       [-1.1834306 ,  2.0462682 ],\n",
      "       [-0.1696132 ,  1.5373276 ],\n",
      "       [-1.5015143 ,  2.595292  ],\n",
      "       [-0.8659425 ,  2.195338  ],\n",
      "       [-0.59721136,  2.2822454 ],\n",
      "       [-1.273857  ,  2.3432393 ],\n",
      "       [-1.2068518 ,  2.3817375 ],\n",
      "       [-0.09938599,  2.0517876 ],\n",
      "       [-0.33747822,  1.391409  ],\n",
      "       [ 0.9448988 ,  0.5791208 ],\n",
      "       [ 0.33167988,  1.4579898 ],\n",
      "       [-1.3505406 ,  2.5073054 ],\n",
      "       [ 0.8000537 , -0.21737112],\n",
      "       [-1.5413476 ,  2.5026667 ],\n",
      "       [-1.5896362 ,  2.560807  ],\n",
      "       [-1.5766195 ,  2.5090587 ],\n",
      "       [-1.4872593 ,  2.4111083 ],\n",
      "       [-1.5558537 ,  2.5567098 ],\n",
      "       [-1.1224364 ,  2.5648775 ],\n",
      "       [ 0.9225797 ,  1.4957366 ],\n",
      "       [-1.1275351 ,  2.346534  ],\n",
      "       [ 1.0241657 ,  1.2980292 ],\n",
      "       [-0.40667492,  2.2743518 ],\n",
      "       [-1.1404399 ,  2.4870775 ],\n",
      "       [-1.0538362 ,  2.1673884 ],\n",
      "       [ 0.84200686,  1.350199  ],\n",
      "       [ 0.35613397,  0.7928381 ],\n",
      "       [-1.5271522 ,  2.4473507 ],\n",
      "       [-1.5058361 ,  2.5909753 ],\n",
      "       [ 0.37288585,  1.8510114 ],\n",
      "       [-1.5823629 ,  2.5916893 ],\n",
      "       [-0.70016974,  1.0358108 ],\n",
      "       [ 0.73148894,  1.4013591 ],\n",
      "       [ 1.2246569 ,  0.0893513 ],\n",
      "       [-1.5707519 ,  2.591957  ],\n",
      "       [-1.2692512 ,  2.481972  ],\n",
      "       [-1.3675123 ,  2.465093  ],\n",
      "       [ 1.0049826 ,  1.2759095 ],\n",
      "       [ 1.4109752 ,  0.0853433 ],\n",
      "       [-0.8455097 ,  1.8619568 ],\n",
      "       [-1.348265  ,  2.4204874 ],\n",
      "       [-0.76015633,  2.2445786 ],\n",
      "       [-1.574266  ,  2.5466309 ],\n",
      "       [-1.3369617 ,  2.3849063 ],\n",
      "       [-1.2559363 ,  2.3666046 ],\n",
      "       [ 0.32986057,  1.086596  ],\n",
      "       [-1.4608643 ,  2.321421  ],\n",
      "       [-1.520802  ,  2.5829408 ],\n",
      "       [ 1.0543395 , -0.3499005 ],\n",
      "       [-1.6141236 ,  2.5390608 ],\n",
      "       [ 1.178764  ,  0.9369137 ],\n",
      "       [ 0.999152  ,  1.345136  ],\n",
      "       [-1.6675488 ,  2.5808308 ],\n",
      "       [-1.4961809 ,  2.6063693 ],\n",
      "       [ 0.3032896 ,  1.0600039 ],\n",
      "       [ 1.6673874 , -0.39155394],\n",
      "       [-1.66849   ,  2.589945  ],\n",
      "       [ 0.1295101 ,  0.77402204],\n",
      "       [-0.28670055,  2.0128937 ],\n",
      "       [-1.4158169 ,  2.362788  ],\n",
      "       [ 1.1730247 ,  1.0188712 ],\n",
      "       [ 1.5436221 ,  0.23100653],\n",
      "       [ 0.52274793, -1.5560054 ],\n",
      "       [ 1.7371473 , -0.23289597],\n",
      "       [ 1.566034  ,  0.37551978],\n",
      "       [-0.8965221 ,  2.1508143 ],\n",
      "       [ 1.0267358 ,  0.66898674],\n",
      "       [-1.6529076 ,  2.5940657 ],\n",
      "       [-0.99020034,  2.005471  ],\n",
      "       [-1.7081959 ,  2.5872438 ],\n",
      "       [-1.3276218 ,  2.5346582 ],\n",
      "       [-1.1699206 ,  2.4301379 ],\n",
      "       [-1.5601977 ,  2.4930594 ],\n",
      "       [-1.6658425 ,  2.5835488 ],\n",
      "       [-0.67777747,  1.3253206 ],\n",
      "       [-1.1755072 ,  2.470288  ],\n",
      "       [-1.5778744 ,  2.548339  ],\n",
      "       [-1.6203673 ,  2.5522244 ],\n",
      "       [-1.5222096 ,  2.4625127 ],\n",
      "       [-1.6180876 ,  2.5668554 ],\n",
      "       [ 0.14210229,  0.90703243],\n",
      "       [-1.0111686 ,  2.0784988 ],\n",
      "       [-1.5179778 ,  2.4485826 ],\n",
      "       [-1.5849428 ,  2.557037  ],\n",
      "       [ 1.1978835 ,  0.95372766],\n",
      "       [-1.1264498 ,  2.5564196 ],\n",
      "       [-1.6332613 ,  2.576752  ],\n",
      "       [-1.6468377 ,  2.5473912 ],\n",
      "       [-1.4434559 ,  2.555752  ],\n",
      "       [-1.6483688 ,  2.6077685 ],\n",
      "       [ 0.2994639 ,  1.8839091 ],\n",
      "       [-1.3485463 ,  2.6172702 ],\n",
      "       [ 0.6106689 , -0.37262964],\n",
      "       [-1.5719479 ,  2.351283  ],\n",
      "       [ 0.79311424,  1.4182831 ],\n",
      "       [-1.3976411 ,  2.5371606 ],\n",
      "       [ 1.0835949 , -1.909525  ],\n",
      "       [ 0.9098297 ,  1.4581131 ],\n",
      "       [-1.0176808 ,  2.53095   ],\n",
      "       [-1.2375778 ,  2.2485864 ],\n",
      "       [-1.3209764 ,  2.533202  ],\n",
      "       [-1.4308461 ,  2.5782967 ],\n",
      "       [ 0.4441629 ,  0.8122191 ],\n",
      "       [-1.2566801 ,  2.4921086 ],\n",
      "       [-1.6284131 ,  2.5732481 ],\n",
      "       [-0.35633934,  0.8030154 ],\n",
      "       [-0.30147094,  1.9930308 ],\n",
      "       [-1.7068337 ,  2.5898082 ],\n",
      "       [-1.3587816 ,  2.394801  ],\n",
      "       [-1.4811631 ,  2.2320273 ],\n",
      "       [ 1.6132725 , -0.39689216],\n",
      "       [ 0.45797032,  1.328584  ],\n",
      "       [-0.95154446,  1.8462738 ],\n",
      "       [-1.5798241 ,  2.576043  ],\n",
      "       [-1.3133329 ,  2.3255212 ],\n",
      "       [-1.1900669 ,  2.3569863 ],\n",
      "       [ 0.5509076 ,  0.8004852 ],\n",
      "       [ 1.1963233 ,  1.0791143 ],\n",
      "       [-1.1501322 ,  2.4552615 ],\n",
      "       [-0.2633325 , -1.061325  ],\n",
      "       [-1.5525411 ,  2.6116278 ],\n",
      "       [-1.476682  ,  2.535758  ],\n",
      "       [-1.4356799 ,  2.5296557 ],\n",
      "       [-1.6053905 ,  2.58156   ],\n",
      "       [ 1.1345594 ,  1.1728922 ],\n",
      "       [-1.6456069 ,  2.6112974 ],\n",
      "       [-1.1142079 ,  2.310933  ],\n",
      "       [ 1.5057542 ,  0.17524037],\n",
      "       [-0.69657046,  2.4308503 ],\n",
      "       [-0.5022433 ,  2.2126398 ],\n",
      "       [-1.5030981 ,  2.5937493 ],\n",
      "       [ 0.0342038 ,  0.64214504],\n",
      "       [-1.6181264 ,  2.5824826 ],\n",
      "       [ 0.05705229,  1.950569  ],\n",
      "       [-1.4970783 ,  2.5185149 ],\n",
      "       [-1.6185528 ,  2.3906274 ],\n",
      "       [-1.245921  ,  2.5034254 ],\n",
      "       [-0.8921791 ,  2.2570567 ],\n",
      "       [-1.657959  ,  2.6043708 ],\n",
      "       [ 0.91519976,  1.3594413 ],\n",
      "       [-0.7629692 ,  2.341853  ],\n",
      "       [-1.6531595 ,  2.6006148 ],\n",
      "       [ 1.3223807 ,  0.9861978 ],\n",
      "       [-1.6300101 ,  2.5167396 ],\n",
      "       [-1.0694581 ,  2.4048393 ],\n",
      "       [ 0.98936015, -2.0479198 ],\n",
      "       [ 0.34088343,  1.8375239 ],\n",
      "       [-1.4986324 ,  2.554043  ],\n",
      "       [ 0.9727372 ,  1.2841471 ],\n",
      "       [-1.216002  ,  2.4593613 ]], dtype=float32), label_ids=array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1]), metrics={'test_loss': 0.4735965430736542, 'test_runtime': 11.8731, 'test_samples_per_second': 34.363, 'test_steps_per_second': 4.295})\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:31:57.283687Z",
     "start_time": "2025-04-01T12:31:57.280906Z"
    }
   },
   "cell_type": "code",
   "source": "preds = np.argmax(predictions.predictions, axis=-1)\n",
   "id": "a4436666bba04b55",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:35:08.580263Z",
     "start_time": "2025-04-01T12:35:00.275977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ],
   "id": "b94713bd7837ed87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.821078431372549, 'f1': 0.884310618066561}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:36:34.115314Z",
     "start_time": "2025-04-01T12:36:34.112441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "id": "7676fe98481969f6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:47:00.838290Z",
     "start_time": "2025-04-01T12:37:11.628784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "8ea107f47b0155ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/perchik/PycharmProjects/Learning_LLMs/.venv/lib/python3.12/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/sd/9sq_fhy14jvdmsklx7t3snqw0000gn/T/ipykernel_24152/1216679267.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 09:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444594</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.864353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552400</td>\n",
       "      <td>0.450502</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.894198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.744780</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.891892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3474955146695361, metrics={'train_runtime': 587.2355, 'train_samples_per_second': 18.739, 'train_steps_per_second': 2.345, 'total_flos': 405114969714960.0, 'train_loss': 0.3474955146695361, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a30caeb5e9ee0ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
